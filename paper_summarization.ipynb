{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 科学論文 PDF 要約ツール\n\nこのノートブックでは `paper_summarizer` モジュールを使って、\n科学論文の PDF を読み込み、構造化された要約を生成する方法を紹介します。\n\n## 主な機能\n- **PDF テキスト抽出**: `PyPDF2` を使用したテキスト抽出\n- **セクション自動検出**: Abstract, Introduction, Methods, Results, Discussion 等を自動認識\n- **TF-IDF 要約**: 各セクションから重要度の高い文を抽出\n- **キーワード抽出**: 論文全体から主要なキーワードを特定\n- **バッチ処理**: 複数論文の一括要約と比較"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 必要なパッケージのインストール（初回のみ）\n# !pip install PyPDF2\n\nfrom paper_summarizer import (\n    summarize_paper,\n    analyze_paper,\n    generate_report,\n    extract_keywords,\n    extract_text_from_pdf,\n    summarize_batch,\n    comparison_table,\n)\n\nprint(\"モジュール読み込み完了\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 単一論文の要約\n",
    "\n",
    "PDF ファイルのパスを指定して `summarize_paper()` を呼ぶだけで、\n",
    "セクション別の要約レポートが生成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- PDF ファイルのパスを指定してください ----\n",
    "pdf_path = \"your_paper.pdf\"  # ← ここを実際のファイルパスに変更\n",
    "\n",
    "# 要約を生成（各セクションから最大3文を抽出）\n",
    "# paper = summarize_paper(pdf_path, sentences_per_section=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 詳細な解析\n",
    "\n",
    "`analyze_paper()` を使うと、プログラムから各セクションの情報に\n",
    "直接アクセスできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 詳細解析の例（PDF パスを指定して実行してください）\n",
    "#\n",
    "# paper = analyze_paper(\"your_paper.pdf\")\n",
    "#\n",
    "# # タイトルとページ数\n",
    "# print(f\"タイトル: {paper.title}\")\n",
    "# print(f\"ページ数: {paper.total_pages}\")\n",
    "# print(f\"キーワード: {', '.join(paper.keywords)}\")\n",
    "# print()\n",
    "#\n",
    "# # 検出されたセクション一覧\n",
    "# for sec in paper.sections:\n",
    "#     n_sent = len(sec.sentences)\n",
    "#     n_summ = len(sec.summary_sentences)\n",
    "#     print(f\"  [{sec.name}] 文数: {n_sent}, 要約文数: {n_summ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. セクション別の要約文を取得\n",
    "\n",
    "特定のセクション（例: Results）の要約文だけを取得することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特定セクションの要約を取り出す例\n",
    "#\n",
    "# paper = analyze_paper(\"your_paper.pdf\")\n",
    "#\n",
    "# for sec in paper.sections:\n",
    "#     if sec.name in [\"Abstract\", \"Results\", \"Conclusion\"]:\n",
    "#         print(f\"\\n=== {sec.name} ===\")\n",
    "#         for i, sent in enumerate(sec.summary_sentences, 1):\n",
    "#             print(f\"  {i}. {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. キーワード抽出\n",
    "\n",
    "論文全体から TF-IDF ベースで重要なキーワードを抽出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# キーワード抽出の例\n",
    "#\n",
    "# raw_text, _ = extract_text_from_pdf(\"your_paper.pdf\")\n",
    "# keywords = extract_keywords(raw_text, top_n=15)\n",
    "#\n",
    "# print(\"抽出されたキーワード:\")\n",
    "# for i, kw in enumerate(keywords, 1):\n",
    "#     print(f\"  {i:2d}. {kw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 複数論文の一括処理と比較\n",
    "\n",
    "ディレクトリ内のすべての PDF を一括で要約し、比較テーブルを出力できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ処理の例\n",
    "#\n",
    "# papers = summarize_batch(\"./papers/\")  # PDF が入ったディレクトリを指定\n",
    "#\n",
    "# # 比較テーブルの出力\n",
    "# if papers:\n",
    "#     table = comparison_table(papers)\n",
    "#     print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. コマンドラインからの使用\n",
    "\n",
    "ターミナルから直接実行することもできます:\n",
    "\n",
    "```bash\n",
    "# 単一論文\n",
    "python paper_summarizer.py paper.pdf\n",
    "\n",
    "# 複数論文\n",
    "python paper_summarizer.py paper1.pdf paper2.pdf paper3.pdf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## デモ: モジュール動作確認\n",
    "\n",
    "PDF ファイルがなくても、モジュールの各関数が正しく動作するか確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_summarizer import (\n",
    "    _split_sentences,\n",
    "    _detect_sections,\n",
    "    _tokenize,\n",
    "    _compute_tf,\n",
    "    _compute_idf,\n",
    "    summarize_section,\n",
    "    PaperSection,\n",
    ")\n",
    "\n",
    "# サンプルテキストでテスト\n",
    "sample_text = \"\"\"Abstract\n",
    "This study investigates the role of peptide vaccines in cancer immunotherapy.\n",
    "We developed a novel neoantigen prediction pipeline using machine learning.\n",
    "Our results demonstrate significant improvement in epitope binding prediction accuracy.\n",
    "\n",
    "Introduction\n",
    "Cancer immunotherapy has revolutionized oncology treatment in recent years.\n",
    "Neoantigen-based vaccines represent a promising personalized approach.\n",
    "However, accurate prediction of immunogenic neoantigens remains challenging.\n",
    "Machine learning methods have shown potential in improving prediction accuracy.\n",
    "\n",
    "Methods\n",
    "We collected peptide-MHC binding data from the IEDB database.\n",
    "A deep learning model was trained on 50000 peptide sequences.\n",
    "Cross-validation was performed using a stratified 5-fold approach.\n",
    "Binding affinity was measured using competitive ELISA assays.\n",
    "\n",
    "Results\n",
    "Our model achieved an AUC of 0.95 on the test dataset.\n",
    "The prediction accuracy improved by 15% compared to existing methods.\n",
    "We identified 23 novel neoantigen candidates from patient tumor samples.\n",
    "In vitro T-cell activation assays confirmed immunogenicity for 18 candidates.\n",
    "\n",
    "Discussion\n",
    "The high prediction accuracy demonstrates the effectiveness of our approach.\n",
    "Integration of structural features significantly improved binding predictions.\n",
    "Our pipeline can be applied to various cancer types for personalized treatment.\n",
    "\n",
    "Conclusion\n",
    "We present a robust neoantigen prediction framework with clinical potential.\n",
    "Future work will focus on clinical validation in phase I trials.\n",
    "\n",
    "References\n",
    "1. Smith et al. Nature 2023.\n",
    "2. Johnson et al. Science 2024.\n",
    "\"\"\"\n",
    "\n",
    "# セクション検出\n",
    "sections = _detect_sections(sample_text)\n",
    "print(\"検出されたセクション:\")\n",
    "for sec in sections:\n",
    "    print(f\"  [{sec.name}] - 文数: {len(sec.sentences)}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF 計算と要約生成\n",
    "all_sentences = []\n",
    "for sec in sections:\n",
    "    all_sentences.extend(sec.sentences)\n",
    "\n",
    "all_docs = [_tokenize(s) for s in all_sentences]\n",
    "idf = _compute_idf(all_docs)\n",
    "\n",
    "# 各セクションの要約（References を除く）\n",
    "skip = {\"References\", \"Acknowledgements\", \"Supplementary\"}\n",
    "for sec in sections:\n",
    "    if sec.name in skip:\n",
    "        continue\n",
    "    summary = summarize_section(sec, idf, max_sentences=2)\n",
    "    print(f\"\\n=== {sec.name} ===\")\n",
    "    for i, sent in enumerate(summary, 1):\n",
    "        print(f\"  {i}. {sent}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}